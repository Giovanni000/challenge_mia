{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Pirate Pain Challenge ‚Äî Exploratory Analysis**\n",
        "\n",
        "---\n",
        "\n",
        "Questa analisi esplora il dataset della Challenge Pirate Pain per supportare un modello GRU monodirezionale (solo GPU) con particolare attenzione ai campioni high pain, che sono rari e critici per le performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üåê **Google Drive Connection**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚öôÔ∏è **Libraries Import**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from typing import Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set(style=\"whitegrid\", context=\"talk\")\n",
        "plt.rcParams[\"figure.figsize\"] = (14, 6)\n",
        "pd.options.display.max_columns = 120\n",
        "pd.options.display.max_rows = 200\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚è≥ **Data Loading**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_DIR = Path('/content/drive/MyDrive/[2025-2026] AN2DL/Challenge')\n",
        "\n",
        "def load_data(data_dir: Path) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
        "    X_train = pd.read_csv(data_dir / 'data' / 'pirate_pain_train.csv')\n",
        "    y_train = pd.read_csv(data_dir / 'data' / 'pirate_pain_train_labels.csv')\n",
        "    X_test = pd.read_csv(data_dir / 'data' / 'pirate_pain_test.csv')\n",
        "    return X_train, y_train, X_test\n",
        "\n",
        "X_train_raw, y_train, X_test_raw = load_data(DATA_DIR)\n",
        "print('X_train shape:', X_train_raw.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print('X_test shape:', X_test_raw.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß **Feature Casting**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure numeric types before aggregations\n",
        "X_train_raw = X_train_raw.copy()\n",
        "X_test_raw = X_test_raw.copy()\n",
        "\n",
        "word_to_num = {\n",
        "    'zero': 0,\n",
        "    'one': 1,\n",
        "    'two': 2,\n",
        "    'three': 3,\n",
        "    'four': 4,\n",
        "    'five': 5,\n",
        "    'six': 6,\n",
        "    'seven': 7,\n",
        "    'eight': 8,\n",
        "    'nine': 9,\n",
        "}\n",
        "\n",
        "def coerce_numeric_counts(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    for col in ['n_legs', 'n_hands', 'n_eyes']:\n",
        "        if col in df.columns:\n",
        "            col_series = df[col].astype(str).str.lower()\n",
        "            numeric_part = pd.to_numeric(col_series, errors='coerce')\n",
        "            word_part = col_series.str.extract('(zero|one|two|three|four|five|six|seven|eight|nine)', expand=False)\n",
        "            word_numeric = word_part.map(word_to_num)\n",
        "            df[col] = numeric_part.fillna(word_numeric)\n",
        "    return df\n",
        "\n",
        "X_train_raw = coerce_numeric_counts(X_train_raw)\n",
        "X_test_raw = coerce_numeric_counts(X_test_raw)\n",
        "\n",
        "# Convert remaining object columns to numeric whenever possible\n",
        "for df in (X_train_raw, X_test_raw):\n",
        "    object_cols = df.select_dtypes(include='object').columns\n",
        "    for col in object_cols:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "X_train_raw[['n_legs', 'n_hands', 'n_eyes']].head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç **First Look**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_raw.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üßº **Data Quality Checks**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "missing_features = X_train_raw.isna().sum().sort_values(ascending=False)\n",
        "missing_labels = y_train.isna().sum()\n",
        "\n",
        "print('Missing values in features (top 10):')\n",
        "print(missing_features.head(10))\n",
        "print('\\nMissing values in labels:')\n",
        "print(missing_labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä **Label Distribution**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "label_counts = y_train['label'].value_counts().rename('count')\n",
        "label_pct = (label_counts / label_counts.sum()).rename('percent') * 100\n",
        "display(pd.concat([label_counts, label_pct], axis=1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ax = sns.countplot(data=y_train, x='label', order=label_counts.index, palette='rocket')\n",
        "ax.bar_label(ax.containers[0])\n",
        "plt.title('Label counts')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚è±Ô∏è **Sequence Structure**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "seq_lengths = X_train_raw.groupby('sample_index').size()\n",
        "print(seq_lengths.describe())\n",
        "\n",
        "coverage = X_train_raw.groupby('sample_index')['time'].agg(['min', 'max'])\n",
        "print('\\nTime coverage per sequence (first 5 samples):')\n",
        "display(coverage.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "high_pain_indices = y_train.loc[y_train['label'] == 'high_pain', 'sample_index']\n",
        "print(f\"# high pain sequences: {len(high_pain_indices)} ({len(high_pain_indices) / len(y_train):.1%})\")\n",
        "print('Sample indices (first 10):', high_pain_indices.head(10).tolist())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß¨ **Feature Dynamics per Label**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "numeric_cols = X_train_raw.select_dtypes(include=np.number).columns\n",
        "\n",
        "survey_cols = [c for c in numeric_cols if c.startswith('pain_survey')]\n",
        "joint_cols = [c for c in numeric_cols if c.startswith('joint_')]\n",
        "count_cols = [c for c in ['n_legs', 'n_hands', 'n_eyes'] if c in numeric_cols]\n",
        "\n",
        "agg_columns = survey_cols + joint_cols + count_cols\n",
        "\n",
        "sequence_summary = (\n",
        "    X_train_raw\n",
        "    .groupby('sample_index')[agg_columns]\n",
        "    .agg(['mean', 'std', 'min', 'max'])\n",
        ")\n",
        "sequence_summary.columns = [f\"{col}_{stat}\" for col, stat in sequence_summary.columns]\n",
        "sequence_summary = sequence_summary.reset_index().merge(y_train, on='sample_index', how='left')\n",
        "sequence_summary.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_cols = [c for c in sequence_summary.columns if c not in ['sample_index', 'label']]\n",
        "label_means = (\n",
        "    sequence_summary[['label'] + feature_cols]\n",
        "    .groupby('label')\n",
        "    .mean(numeric_only=True)\n",
        ")\n",
        "contrast = label_means.loc['high_pain'] - label_means.drop('high_pain').mean()\n",
        "contrast.sort_values(key=np.abs, ascending=False).head(15)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "top_diff = contrast.sort_values(key=np.abs, ascending=False).head(20)\n",
        "plt.figure(figsize=(14, 6))\n",
        "ax = sns.barplot(x=top_diff.values, y=top_diff.index, palette='coolwarm', orient='h')\n",
        "plt.axvline(0, color='black', linewidth=1)\n",
        "plt.title('High pain vs (low + no pain) mean difference')\n",
        "plt.xlabel('Mean difference')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü©π **Pain Survey Signals Over Time**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "survey_variability = (\n",
        "    X_train_raw\n",
        "    .groupby('sample_index')[survey_cols]\n",
        "    .nunique()\n",
        ")\n",
        "print('Unique values per survey feature across timesteps (describe):')\n",
        "display(survey_variability.describe())\n",
        "print('\\nShare of sequences with constant survey values:')\n",
        "constant_share = (survey_variability == 1).mean().sort_values(ascending=False)\n",
        "display(constant_share)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "survey_mean_cols = [c for c in sequence_summary.columns if c.startswith('pain_survey_') and c.endswith('_mean')]\n",
        "survey_melt = sequence_summary[['label'] + survey_mean_cols].melt(id_vars='label', var_name='survey', value_name='mean_value')\n",
        "survey_melt['survey'] = survey_melt['survey'].str.replace('_mean', '', regex=False)\n",
        "plt.figure(figsize=(14, 6))\n",
        "ax = sns.boxplot(data=survey_melt, x='survey', y='mean_value', hue='label', palette='rocket', showfliers=False)\n",
        "plt.title('Distribution of mean survey values per label')\n",
        "plt.ylabel('Mean value across time')\n",
        "plt.legend(title='Label')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü¶¥ **Joint Sensor Highlights for High Pain**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joint_diff = contrast[contrast.index.str.startswith('joint_')]\n",
        "joint_diff = joint_diff.sort_values(key=np.abs, ascending=False).head(30)\n",
        "plt.figure(figsize=(14, 10))\n",
        "ax = sns.barplot(x=joint_diff.values, y=joint_diff.index, palette='vlag', orient='h')\n",
        "plt.axvline(0, color='black', linewidth=1)\n",
        "plt.title('Top joint statistics differentiating high pain sequences')\n",
        "plt.xlabel('High pain mean ‚àí others mean')\n",
        "plt.ylabel('Joint feature (statistic)')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚è≥ **Sample Trajectories**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "example_high = high_pain_indices.iloc[0]\n",
        "example_low = y_train.loc[y_train['label'] == 'low_pain', 'sample_index'].iloc[0]\n",
        "example_no = y_train.loc[y_train['label'] == 'no_pain', 'sample_index'].iloc[0]\n",
        "\n",
        "features_to_plot = ['pain_survey_1', 'pain_survey_2', 'joint_00', 'joint_15']\n",
        "examples = {\n",
        "    'high_pain': example_high,\n",
        "    'low_pain': example_low,\n",
        "    'no_pain': example_no,\n",
        "}\n",
        "\n",
        "fig, axes = plt.subplots(len(features_to_plot), 1, figsize=(14, 10), sharex=True)\n",
        "for ax, feature in zip(axes, features_to_plot):\n",
        "    for label, idx in examples.items():\n",
        "        subset = X_train_raw.loc[X_train_raw['sample_index'] == idx]\n",
        "        ax.plot(subset['time'], subset[feature], label=label if feature == features_to_plot[0] else None)\n",
        "    ax.set_title(feature)\n",
        "    ax.set_xlabel('time')\n",
        "\n",
        "handles, labels = axes[0].get_legend_handles_labels()\n",
        "fig.legend(handles, labels, loc='upper right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚öñÔ∏è **Class Imbalance Signals**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "other_mask = sequence_summary['label'] != 'high_pain'\n",
        "feature_cols = [c for c in sequence_summary.columns if c not in ['sample_index', 'label']]\n",
        "features_high = sequence_summary.loc[~other_mask, feature_cols]\n",
        "features_other = sequence_summary.loc[other_mask, feature_cols]\n",
        "\n",
        "mean_high = features_high.mean(numeric_only=True)\n",
        "mean_other = features_other.mean(numeric_only=True)\n",
        "var_high = features_high.var(numeric_only=True)\n",
        "var_other = features_other.var(numeric_only=True)\n",
        "\n",
        "n_high = len(features_high)\n",
        "n_other = len(features_other)\n",
        "pooled_std = np.sqrt(((n_high - 1) * var_high + (n_other - 1) * var_other) / (n_high + n_other - 2))\n",
        "pooled_std = pooled_std.replace(0, np.nan)\n",
        "cohens_d = (mean_high - mean_other) / pooled_std\n",
        "cohens_d = cohens_d.dropna().sort_values(key=np.abs, ascending=False)\n",
        "cohens_d.head(20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "top_effect = cohens_d.head(25)\n",
        "plt.figure(figsize=(14, 8))\n",
        "ax = sns.barplot(x=top_effect.values, y=top_effect.index, palette='Spectral', orient='h')\n",
        "plt.axvline(0, color='black', linewidth=1)\n",
        "plt.title(\"Cohen's d between high pain and other classes\")\n",
        "plt.xlabel(\"Effect size (œÉ)\")\n",
        "plt.ylabel(\"Feature statistic\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß© **Body Part Counts (n_legs, n_hands, n_eyes)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "count_mean_cols = [f'{col}_mean' for col in count_cols]\n",
        "count_std_cols = [f'{col}_std' for col in count_cols]\n",
        "count_summary = sequence_summary[['label'] + count_mean_cols + count_std_cols]\n",
        "count_summary_mean = count_summary.groupby('label')[count_mean_cols].mean()\n",
        "count_summary_std = count_summary.groupby('label')[count_std_cols].mean()\n",
        "print('Mean counts per label:')\n",
        "display(count_summary_mean)\n",
        "print('\\nAverage temporal variability per label:')\n",
        "display(count_summary_std)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìù **Research Questions & Next Steps**\n",
        "\n",
        "- Rafforzare la modellazione delle feature pi√π discriminanti individuate (survey e articolazioni con maggiore effetto size) magari con normalizzazioni dedicate.\n",
        "- Valutare strategie di upsampling o loss reweighting per ridurre l'impatto dell'imbalance dei 56 soggetti high pain.\n",
        "- Considerare feature engineering temporale (derivate, slope, trend) sui joint e sulle survey per alimentare la GRU monodirezionale.\n",
        "- Analizzare ulteriormente i pattern dinamici dei pochi high pain (clustering, DTW) per capire quali firme preservare durante l'augmentation.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
